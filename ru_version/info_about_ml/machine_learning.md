# Общая информация о машинном обучении

## Содержание
1. [Что такое машинное обучение](#что-такое-машинное-обучение)
2. [Какие задачи решает машинное обучение](#какие-задачи-решает-машинное-обучение)
3. [Исследовательский анализ факторов](#исследовательский-анализ-факторов)
4. [Подготовка факторов](#подготовка-факторов)
5. [Выбор и создание модели](#выбор-и-создание-модели)
6. [Подбор гиперпараметров модели](#подбор-гиперпараметров-модели)
7. [Оценка качества модели](#оценка-качества-модели)
8. [Заключение](#заключение)

---

## Что такое машинное обучение

### Основное определение
Машинное обучение (Machine Learning) — это раздел искусственного интеллекта, который изучает методы построения алгоритмов, способных обучаться на данных и делать прогнозы или принимать решения без явного программирования.

### Как это работает
Вместо того чтобы писать строгие правила (как в обычном программировании), мы "показываем" алгоритму много примеров и он сам находит закономерности в данных.

### Типы машинного обучения
- **Обучение с учителем (Supervised Learning)**: есть размеченные данные с правильными ответами (метками)
- **Обучение без учителя (Unsupervised Learning)**: ищем структуру в данных без меток
- **Обучение с подкреплением (Reinforcement Learning)**: алгоритм учится на собственных действиях и их последствиях с помощью функции награды

---

## Какие задачи решает машинное обучение

### Бинарная классификация
Отнесение объектов к двум определенным категориям. Например:
- Котики/собачки на фотографии
- Хороший клиент/плохой клиент

### Многоклассовая классификация
Отнесение объектов к произвольному количеству определенных категорий. Например:
- Определение числа на изображении
- Определение сорта розы по фотографии

### Регрессия
Предсказание числовых значений. Например:
- Цена квартиры
- Температура воздуха завтра
- Количество продаж в магазине

### Кластеризация
Группировка похожих объектов без заранее известных меток. Например:
- Сегментация клиентов
- Группировка документов по темам

### Другие задачи
- **Обнаружение аномалий**: поиск необычных объектов
- **Уменьшение размерности**: упрощение данных без потери важной информации
- **Рекомендательные системы**: подбор товаров/фильмов пользователю

---

## Исследовательский анализ факторов

### Зачем это нужно
Прежде чем строить модель, нужно понять с какими данными придется работать. Это помогает:
- Найти ошибки в данных
- Обнаружить выбросы в данных
- Обнаружить пропуски в данных
- Увидеть закономерности в данных
- Выбрать правильные методы обработки данных

### Основные методы анализа

#### Описательная статистика
Для начала работы целесообразно провести первичный анализ данных, включая расчет базовых статистических показателей.

Пример кода:

```python
import pandas as pd

data = pd.read_csv('data.csv')
print(data.describe())  # основные статистики
print(data.info())      # информация о типах данных
print(data.head())      # первые строки данных
```

#### Визуализация
- **Гистограммы**: распределение числовых признаков
- **Диаграммы рассеяния**: связь между двумя признаками
- **Box plots**: поиск выбросов
- **Heatmaps**: корреляции между признаками

#### Анализ корреляций
Поиск признаков, связанных между собой и  с целевой переменной.

Пример кода:

```python
correlation_matrix = data.corr()
```

---

## Подготовка факторов

### Обработка пропущенных значений
- **Удаление**: удаление данных с пропусками, если их не много
- **Замена**: замена пропусков, например, медианным значением
- **Предсказание**: предсказание пропущенных значений с помощью других моделей

### Кодирование категориальных признаков
- **One-Hot Encoding**: разбиение категории на бинарные факторы
- **Label Encoding**: присваивание числа категориям
- **Target Encoding**: замена категории средним значением целевой переменной

### Масштабирование признаков
Для корректной работы многих алгоритмов машинного обучения требуется масштабирование факторов. Это обеспечивает сходимость модели, уравнивая влияние каждого признака на процесс обновления весов.

Пример кода:

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
```

### Работа с выбросами
**Выбросы (outliers)** — это наблюдения в данных, которые значительно отличаются от остальных значений и могут быть вызваны ошибками измерения, редкими событиями или естественной изменчивостью данных. Выбросы могут сильно искажать результаты анализа и ухудшать качество моделей машинного обучения.

Методы обработки выбросов:
- **Удаление**: удаление явно ошибочных выбросов
- **Замена**: замена выбросов граничными значениями
- **Преобразование**: логарифмирование для уменьшения влияния выбросов

---

## Выбор и создание модели

### Как выбрать модель
Выбор модели зависит от поставленной задачи и имеющихся данных:

#### Ключевые критерии выбора модели:
- **Размер данных**: маленький/большой датасет
- **Интерпретируемость**: нужно ли объяснять предсказания
- **Скорость обучения**: как быстро должна обучаться модель
- **Тип задачи**: классификация, регрессия, кластеризация
- **Линейность данных**: линейные или сложные нелинейные зависимости

#### Для классификации
- **Логистическая регрессия**: простой и интерпретируемый метод, хорошо работает когда классы линейно разделимы
- **Деревья решений**: легко понять, но склонны к переобучению, хорошо для нелинейных зависимостей
- **Случайный лес**: устойчивее к переобучению, но сложнее интерпретировать, хорошо для большинства задач
- **Метод опорных векторов (SVM)**: хорошо для сложных границ, но медленный на больших данных

#### Для регрессии
- **Линейная регрессия**: базовый метод, хорошо когда зависимость линейная
- **Деревья регрессии**: нелинейные зависимости, но склонны к переобучению
- **Случайный лес для регрессии**: ансамблевый метод, устойчивый к шуму
- **Ridge/Lasso регрессия**: с регуляризацией, когда много признаков

### Процесс создания модели
Пример кода:

```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Разделение данных
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

# Создание и обучение модели
model = RandomForestClassifier()
model.fit(x_train, y_train)

# Предсказание модели
y_pred = model.predict(x_test)
```

---

## Подбор гиперпараметров модели

### Что такое гиперпараметры
Это глобальные параметры (настройки модели), которые не обучаются на данных, а задаются заранее. Например:
- Глубина дерева
- Скорость обучения модели
- Количество деревьев в лесу

### Методы подбора гиперпараметров

#### Grid Search
Перебирает все комбинации из заданного набора гиперпараметров.

Пример кода:

```python
from sklearn.model_selection import GridSearchCV

parameters = {
    'max_depth': [5, 10, 15],
    'min_samples_leaf': [1, 5, 10]
}

grid_search = GridSearchCV(model, parameters, cv=5)
grid_search.fit(X_train, y_train)
```

#### Random Search
Случайно выбирает комбинации из заданных распределений.

Пример кода:

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

param_distributions = {
    'n_estimators': randint(50, 200),           # случайное целое от 50 до 200
    'max_depth': randint(3, 15),                # случайное целое от 3 до 15
    'min_samples_split': randint(2, 20),        # случайное целое от 2 до 20
    'min_samples_leaf': randint(1, 10),         # случайное целое от 1 до 10
    'max_features': ['sqrt', 'log2', None],     # категориальный параметр
    'bootstrap': [True, False]                  # булевский параметр
}

random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_distributions,
    n_iter=50,                                  # количество случайных комбинаций
    cv=5,                                       # количество фолдов кросс-валидации
    random_state=52,                            # для воспроизводимости
    n_jobs=-1                                   # использовать все процессоры
)

random_search.fit(x_train, y_train)

# Лучшие параметры и оценка
print('Лучшие параметры:', random_search.best_params_)
print('Лучшая оценка:', random_search.best_score_)
```

#### Cross-Validation
Разбивает данные на несколько частей и поочередно использует их для обучения и проверки модели.

Пример кода:

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, x_train, y_train, cv=5)
print(f'Средняя точность: {scores.mean()}')
```

---

## Оценка качества модели

### Для классификации

#### Матрица ошибок
Показывает, сколько объектов каждого класса правильно классифицированы:

<div align="center">

<table>
    <tr align="center">
        <th>Метрика</th>
        <th>Формула</th>
        <th>Интерпретация</th>
    </tr>
    <tr align="center">
        <td><strong>Accuracy</strong></td>
        <td><code>(TP + TN) / (TP + TN + FP + FN)</code></td>
        <td>Общая доля верных предсказаний</td>
    </tr>
    <tr align="center">
        <td><strong>Precision</strong></td>
        <td><code>TP / (TP + FP)</code></td>
        <td>Точность положительных предсказаний</td>
    </tr>
    <tr align="center">
        <td><strong>Recall</strong></td>
        <td><code>TP / (TP + FN)</code></td>
        <td>Полнота положительных предсказаний</td>
    </tr>
    <tr align="center">
        <td><strong>F1-score</strong></td>
        <td><code>2 * (Precision * Recall) / (Precision + Recall)</code></td> <td>Гармоническое среднее precision и recall</td>
    </tr>
</table>

</div>

#### Основные метрики
- **Accuracy**: общая точность правильности предсказаний модели
- **Precision**: точность положительных предсказаний модели
- **Recall**: полнота обнаружения положительных классов моделей
- **F1-score**: баланс между precision и recall
- **ROC-AUC**: площадь под ROC-кривой

### Для регрессии
- **MSE**: средняя квадратичная ошибка
- **MAE**: средняя абсолютная ошибка
- **R²**: коэффициент детерминации

### Бутстрап и доверительные интервалы
С помощью бустрапа можно оценить надежность метрик качества, построив их доверительные интервалы.

Пример кода (`decision_tree/model.py`):

```python
# Объединение тестовых данных
x_y_test = x_test.copy(deep=True)
x_y_test['label'] = y_test

boot_accuracies = []
boot_precisions = []
boot_recalls = []
boot_f1_scores = []

n_bootstraps = 1000

print(f'\n\nВыполняется бутстрап ({n_bootstraps} итераций)...')
for i in range(n_bootstraps):
    if (i + 1) % 100 == 0:
        print(f'Завершено итераций: {i + 1}/{n_bootstraps}')

    # Создание бутстрап-выборки
    x_y_test_boot = x_y_test.sample(len(x_y_test), replace=True)
    x_test_boot = x_y_test_boot.drop(columns='label')
    y_test_boot = x_y_test_boot['label']

    # Предсказания модели
    y_pred = best_model.predict(x_test_boot)

    # Вычисление метрик качества
    boot_accuracies.append(accuracy_score(y_test_boot, y_pred))
    boot_precisions.append(precision_score(y_test_boot, y_pred,
                                         average='weighted', zero_division=0))
    boot_recalls.append(recall_score(y_test_boot, y_pred,
                                   average='weighted', zero_division=0))
    boot_f1_scores.append(f1_score(y_test_boot, y_pred,
                                 average='weighted', zero_division=0))

def calculate_confidence_interval(metric_values):
    """Вычисляет доверительные интервалы (95%)"""
    sorted_metrics = np.sort(metric_values)
    lower_bound = sorted_metrics[int(0.025 * len(sorted_metrics))]
    upper_bound = sorted_metrics[int(0.975 * len(sorted_metrics))]
    return lower_bound, upper_bound

accuracy_ci = calculate_confidence_interval(boot_accuracies)
precision_ci = calculate_confidence_interval(boot_precisions)
recall_ci = calculate_confidence_interval(boot_recalls)
f1_ci = calculate_confidence_interval(boot_f1_scores)

# Вывод доверительных интервалов
print('\n\nДоверительные интервалы метрик (бутстрап):')
print('Accuracy:')
print(f'Среднее значение интервала: {best_test_accuracy}')
print(f'Интервал: [{accuracy_ci[0]}, {accuracy_ci[1]}]')
print(f'Описание интервала: (95% ДИ, ширина: {
    accuracy_ci[1] - accuracy_ci[0]})')

print('\nPrecision:')
print(f'Среднее значение интервала: {best_test_precision}')
print(f'Интервал: [{precision_ci[0]}, {precision_ci[1]}]')
print(f'Описание интервала: (95% ДИ, ширина: {
    precision_ci[1] - precision_ci[0]})')

print('\nRecall:')
print(f'Среднее значение интервала: {best_test_recall}')
print(f'Интервал: [{recall_ci[0]}, {recall_ci[1]}]')
print(f'Описание интервала: (95% ДИ, ширина: {recall_ci[1] - recall_ci[0]})')

print('\nF1:')
print(f'Среднее значение интервала: {best_test_f1}')
print(f'Интервал: [{f1_ci[0]}, {f1_ci[1]}]')
print(f'Описание интервала: (95% ДИ, ширина: {f1_ci[1] - f1_ci[0]})')
```

---

## Заключение
Машинное обучение — это мощный инструмент для решения сложных задач, где традиционное программирование не справляется. Главное — понимать, какая задача стоит перед разработчиком, тщательно подготовить данные, выбрать подходящую модель и правильно оценить ее качество.
